{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr as eo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train_train_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61Am7goxaF...</td>\n",
       "      <td>178778</td>\n",
       "      <td>depth</td>\n",
       "      <td>3.9 centimetre</td>\n",
       "      <td>607ba212-cce4-40b9-9f5e-c554e62ce964.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51R8AlSuVK...</td>\n",
       "      <td>347320</td>\n",
       "      <td>depth</td>\n",
       "      <td>100.0 inch</td>\n",
       "      <td>cea75d65-b014-4063-8266-92d02333aecf.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51KghPIV6J...</td>\n",
       "      <td>826444</td>\n",
       "      <td>depth</td>\n",
       "      <td>90.0 millimetre</td>\n",
       "      <td>18dcc8fb-3d55-4210-b0bc-5cdb125e23e0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51gqMA7+K0...</td>\n",
       "      <td>494658</td>\n",
       "      <td>depth</td>\n",
       "      <td>53.0 centimetre</td>\n",
       "      <td>720519e2-2a97-441d-8aba-1269b767d168.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51YDWb+0+m...</td>\n",
       "      <td>861555</td>\n",
       "      <td>depth</td>\n",
       "      <td>217.0 millimetre</td>\n",
       "      <td>ad84886e-4f36-4fd5-aac2-0b8a1fb18fef.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61Am7goxaF...    178778       depth   \n",
       "1  https://m.media-amazon.com/images/I/51R8AlSuVK...    347320       depth   \n",
       "2  https://m.media-amazon.com/images/I/51KghPIV6J...    826444       depth   \n",
       "3  https://m.media-amazon.com/images/I/51gqMA7+K0...    494658       depth   \n",
       "4  https://m.media-amazon.com/images/I/51YDWb+0+m...    861555       depth   \n",
       "\n",
       "       entity_value                                image_name  \n",
       "0    3.9 centimetre  607ba212-cce4-40b9-9f5e-c554e62ce964.jpg  \n",
       "1        100.0 inch  cea75d65-b014-4063-8266-92d02333aecf.jpg  \n",
       "2   90.0 millimetre  18dcc8fb-3d55-4210-b0bc-5cdb125e23e0.jpg  \n",
       "3   53.0 centimetre  720519e2-2a97-441d-8aba-1269b767d168.jpg  \n",
       "4  217.0 millimetre  ad84886e-4f36-4fd5-aac2-0b8a1fb18fef.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_link', 'group_id', 'entity_name', 'entity_value', 'image_name'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarthaktanwar/Coding/python-projects/Amazon-ML-2024/amazonenv/lib/python3.12/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/Users/sarthaktanwar/Coding/python-projects/Amazon-ML-2024/amazonenv/lib/python3.12/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "reader = eo.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'dataset/Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from image\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        # Read the image and extract text\n",
    "        simple_result = reader.readtext(image_path, detail=0)  # detail=0 gives just the text\n",
    "        # detailed_result = reader.readtext(image_path)  # full output\n",
    "\n",
    "        result = [string for string in simple_result if re.search(r'\\d', string)]\n",
    "\n",
    "\n",
    "        # Convert all elements of detailed_result to string to avoid serialization issues\n",
    "        # detailed_result_serializable = [[str(item) for item in sublist] for sublist in detailed_result]\n",
    "\n",
    "        return result     #   , detailed_result_serializable  # Return the list of extracted text\n",
    "    except Exception as e:\n",
    "        return str(e), str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extracted_info'] = \"\"\n",
    "# df['full_info'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from an image using the index in the CSV\n",
    "def extract_text_by_index(index):\n",
    "    if index < len(df):\n",
    "        image_name = df.loc[index, 'image_name']  # Get the image name based on the index\n",
    "        image_path = os.path.join('dataset/Training', image_name)  # Replace with your folder path\n",
    "        \n",
    "        # Extract text from the image\n",
    "        result = reader.readtext(image_path, detail=0)  # detail=0 gives just the text\n",
    "        print(result)\n",
    "        result = [string for string in result if re.search(r'\\d', string)]\n",
    "        print(result)\n",
    "        # Print the extracted text\n",
    "        print(f\"Extracted Text from {image_name}: {result}\")\n",
    "    else:\n",
    "        print(\"Index out of range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Design Scale', '(12 inch X 12 inch)', '}', 'inch', '12']\n",
      "['(12 inch X 12 inch)', '12']\n",
      "Extracted Text from e4438f72-a8e8-4fb0-8479-059fb6e2142d.jpg: ['(12 inch X 12 inch)', '12']\n"
     ]
    }
   ],
   "source": [
    "extract_text_by_index(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing CSV file\n",
    "output_folder = 'dataset/'  # Replace with your desired output folder path\n",
    "output_file = os.path.join(output_folder, 'train_train_train_train.csv')\n",
    "df = pd.read_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n"
     ]
    }
   ],
   "source": [
    "# # Loop through the DataFrame and update the columns\n",
    "# for index, row in df.iterrows():\n",
    "#     if index < 400:\n",
    "#         image_path = os.path.join(image_folder, row['image_name'])\n",
    "        \n",
    "#         # Extract text\n",
    "#         simple_result = extract_text_from_image(image_path)\n",
    "        \n",
    "#         print(index)\n",
    "#         # Store the results in the corresponding columns\n",
    "#         df.at[index, 'extracted_info'] = simple_result  # Store simple text\n",
    "        \n",
    "#         # Convert the detailed result to a JSON string to avoid Pandas storing issues\n",
    "#         # df.at[index, 'full_info'] = json.dumps(detailed_result)  # Store detailed output as JSON\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "\n",
    "# Loop through the DataFrame and update the columns for the next chunk\n",
    "for index, row in df.iterrows():\n",
    "    if 1300 <= index < len(df)+1:\n",
    "        image_path = os.path.join(image_folder, row['image_name'])\n",
    "        \n",
    "        # Extract text\n",
    "        simple_result = extract_text_from_image(image_path)\n",
    "        \n",
    "        print(index)\n",
    "        # Store the results in the corresponding columns\n",
    "        df.at[index, 'extracted_info'] = simple_result  # Store simple text\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed rows all. The results have been saved to dataset/train_train_train_train.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Define the folder where you want to save the CSV\n",
    "# output_folder = 'dataset/'  # Replace with your desired output folder path\n",
    "\n",
    "# # Ensure the output folder exists\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Define the full path for the output CSV file\n",
    "# output_file = os.path.join(output_folder, 'train_train_train_train.csv')\n",
    "\n",
    "# # Save the updated DataFrame to the new CSV file in the specific folder\n",
    "# df.to_csv(output_file, index=False)\n",
    "\n",
    "# print(f\"Text extraction complete! The results have been saved to {output_file}.\")\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed rows all. The results have been saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
